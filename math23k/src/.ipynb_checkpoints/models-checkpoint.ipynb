{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSeq(nn.Module):\n",
    "    ...\n",
    "    def forward(self,\n",
    "                input_seqs,\n",
    "                input_lengths,\n",
    "                batch_graph,\n",
    "                hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "\n",
    "        # input_seqs:    [seq_len, batch_size]\n",
    "        # input_lengths: [batch_size]\n",
    "        # batch_graph:   [batch_size, 5, seq_len, seq_len]\n",
    "\n",
    "        embedded = self.embedding(input_seqs)  # S x B x E\n",
    "        embedded = self.em_dropout(embedded)\n",
    "        # embedded:   [seq_len, batch_size, embedding_size]\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        pade_hidden = hidden\n",
    "\n",
    "        pade_outputs, pade_hidden = self.gru_pade(packed, pade_hidden)\n",
    "        pade_outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(pade_outputs)\n",
    "        # pade_outputs: [seq_len,   batch_size, 2*hidden_size]\n",
    "        # pade_hidden:  [2*n_layer, batch_size,   hidden_size]\n",
    "\n",
    "        problem_output = pade_outputs[-1, :, :self.hidden_size] + pade_outputs[0, :, self.hidden_size:]\n",
    "        pade_outputs   = pade_outputs[ :, :, :self.hidden_size] + pade_outputs[:, :, self.hidden_size:]  # S x B x H\n",
    "        # problem_output: [batch_size, hidden_size]\n",
    "        # pade_outputs:   [seq_len, batch_size, hidden_size]\n",
    "\n",
    "        _, pade_outputs = self.gcn(pade_outputs, batch_graph)\n",
    "        # pade_outputs: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        pade_outputs = pade_outputs.transpose(0, 1)\n",
    "        # pade_outputs: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "        return pade_outputs, problem_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Node Representation**  \n",
    "**Module:** BiLSTM neural network  \n",
    "**Output:**  \n",
    "$$H = \\{h_{1}, ..., h_{N}\\} \\in R^{N \\times d}, N = m + l$$\n",
    "$d$ denotes the dimension of hidden vectors  \n",
    "$m$ represents the number of words  \n",
    "$l$ represents the number of quantities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std  = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff ,d_out, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 4层GCN网络\n",
    "        self.graph = clones(module=GCN(in_feat_dim=indim,\n",
    "                                       nhid=hiddim,\n",
    "                                       out_feat_dim=self.d_k,\n",
    "                                       dropout=dropout),\n",
    "                            N=4)\n",
    "        \n",
    "        self.feed_foward = PositionwiseFeedForward(indim, hiddim, outdim, dropout)\n",
    "        self.norm = LayerNorm(outdim)\n",
    "\n",
    "    def forward(self, graph_nodes, graph):\n",
    "        # graph_nodes: [seq_len, batch_size, hidden_size]\n",
    "        # graph:       [batch_size, 5, seq_len, seq_len]\n",
    "        nbatches = graph_nodes.size(0)\n",
    "        mbatches = graph.size(0)\n",
    "        if nbatches != mbatches:\n",
    "            graph_nodes = graph_nodes.transpose(0, 1)\n",
    "        # graph_nodes: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # adj (batch_size, K, K): adjacency matrix\n",
    "\n",
    "        # graph.numel(): 返回数组中的元素个数\n",
    "        if not bool(graph.numel()):\n",
    "            adj = self.get_adj(graph_nodes)\n",
    "            adj_list = [adj, adj, adj, adj]\n",
    "        else:\n",
    "            adj = graph.float()\n",
    "            # adj: [batch_size, 5, seq_len, seq_len]\n",
    "            # adj[:, 1, :]: Quantity Comparison Graph\n",
    "            # adj[:, 4, :]: Quantity Cell       Graph\n",
    "            adj_list = [adj[:, 1, :], adj[:, 1, :], adj[:, 4, :], adj[:, 4, :]]\n",
    "\n",
    "        g_feature = tuple([l(graph_nodes, x) for l, x in zip(self.graph, adj_list)])\n",
    "        # g_feature: (\n",
    "        #   [batch_size, seq_len, outdim],\n",
    "        #   [batch_size, seq_len, outdim],\n",
    "        #   [batch_size, seq_len, outdim],\n",
    "        #   [batch_size, seq_len, outdim]\n",
    "        # )\n",
    "        # hidden_size = outdim * 4\n",
    "\n",
    "        g_feature = self.norm(torch.cat(g_feature, dim=2)) + graph_nodes  # Norm & Add\n",
    "        # g_feature: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        graph_encode_features = self.feed_foward(g_feature) + g_feature   # Norm & Add\n",
    "        # graph_encode_features: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # adj: [batch_size, 5, seq_len, seq_len]\n",
    "        return adj, graph_encode_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph Transformer:**  \n",
    "  \n",
    "**Graph_Module**:  \n",
    "**inputs:**  \n",
    "* adjacency matrices of multiple graphs $\\{A_{k}\\}_{k=1}^{K}$\n",
    "* initial node embeddings $H$\n",
    "* Quantity Comparison Graph $adj[:, 1, :]$\n",
    "* Quantity Cell Graph $adj[:, 4, :]$\n",
    "  \n",
    "**outputs**: \n",
    "* adjacency matrices of multiple graphs $\\{A_{k}\\}_{k=1}^{K}$\n",
    "* graph representation $z_{g}$\n",
    "  \n",
    "**model**:  \n",
    "* for each graph $\\{A_{k}\\}_{k=1}^{K}$, where $K=4$, concatenate GCN learning\n",
    "* each GCN output = $[batch\\_size, seq\\_len, outdim]$, and $outdim=hidden\\_size / 4$  \n",
    "$$Z = \\overset{K}{\\underset{k=1}{\\parallel}} GCN(A_{k}, H)$$\n",
    "* $\\parallel$ denote the concatenation of the K GCN heads.  \n",
    "* GCN layer = Layer Normalization layer + Residual Connection\n",
    "$$\\hat{Z} = Z + LayerNorm(Z)$$\n",
    "* Feed-Forward Network FFN(two layer feed-forward network with relu function between layers)  \n",
    "$$FFN(x) = max(0, x W_{f1} + b_{f1}) W_{f2} + b_{f2}$$\n",
    "* feed-forward network sub-layer\n",
    "$$\\bar{Z} = \\hat{Z} + LayerNorm(FFN(\\hat{Z}))$$\n",
    "* **(not mentioned)** min-pooling operation on all learned node representations, then fed into fully connected neural network(FC) to generate the graph representation\n",
    "$$Z_{g} = FC(MinPool(\\bar{Z}))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.gc1 = GraphConvolution(in_feat_dim, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, out_feat_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GCN**  \n",
    "  \n",
    "**Inputs:**  \n",
    "* adjacency matrix which represent the graph structure $A_{k}$\n",
    "* feature matrix which mean the input feature of all nodes $X$\n",
    "  \n",
    "**Outputs:**  \n",
    "* graph node feature\n",
    "  \n",
    "**model**:  \n",
    "$$GCN(A_{k}, X) = GConv_{2}(A_{k}, GConv_{1}(A_{k}, X))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "# Graph_Conv\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # input: [batch_size, seq_len, in_features]\n",
    "        support = torch.matmul(input, self.weight)  # input * weight\n",
    "        # support: [batch_size, seq_len, out_features]\n",
    "        output  = torch.matmul(adj, support)  # adj * input * weight\n",
    "        # output: [batch_size, seq_len, out_features]\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphConv**  \n",
    "  \n",
    "**input:**  \n",
    "* graph node representations $X = input$\n",
    "* adjancency matrix $A_{k} = adj$\n",
    "    \n",
    "**output:**  \n",
    "* graph updated feature \n",
    "  \n",
    "**model:**  \n",
    "$$GConv(A_{k}, X) = relu(A_{k} X^{T} W_{gk})$$  \n",
    "其中，$W_{gk} \\in R^{d \\times d_{k}}$, where $d_k = d/K$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    ...\n",
    "    def forward(self,\n",
    "                node_stacks,\n",
    "                left_childs,\n",
    "                encoder_outputs,\n",
    "                num_pades,\n",
    "                padding_hidden,\n",
    "                seq_mask,\n",
    "                mask_nums):\n",
    "\n",
    "        current_embeddings = []\n",
    "        for st in node_stacks:  # node_stacks记录节点的goal vector q\n",
    "            if len(st) == 0:\n",
    "                current_embeddings.append(padding_hidden)\n",
    "            else:\n",
    "                current_node = st[-1]\n",
    "                current_embeddings.append(current_node.embedding)\n",
    "\n",
    "        # ** left_childs:          subtree embedding t\n",
    "        # ** current_embeddings:   goal vector q\n",
    "\n",
    "        # len(left_childs):        batch_size\n",
    "        # len(current_embeddings): batch_size\n",
    "        # left_childs item:        [1, hidden_size]\n",
    "        # current_embeddings item: [1, hidden_size]\n",
    "        # 初始时，current_embeddings为problem_output\n",
    "\n",
    "        current_node_temp = []  # updated goal vector q\n",
    "        for l, c in zip(left_childs, current_embeddings):\n",
    "            if l is None:  # left sub-tree embedding is None, generate left child node\n",
    "                # 在初始化根节点时，h_l为problem_text\n",
    "\n",
    "                # 2. Left Sub-Goal Generation\n",
    "                # 若此时左子树为空，则生成左孩子节点\n",
    "                c = self.dropout(c)                   # h_l\n",
    "                g = torch.tanh(   self.concat_l(c))   # Q_{le}\n",
    "                t = torch.sigmoid(self.concat_lg(c))  # g_l\n",
    "                current_node_temp.append(g * t)       # q_l\n",
    "\n",
    "            else:  # left sub-tree embedding is not None, generate right child node\n",
    "\n",
    "                # 3. Right Sub-Goal Generation\n",
    "                # 若此时左子树不为空，则生成右孩子节点\n",
    "                # 当左孩子为叶子节点时，sub-tree embedding为embedding matrix，否则由sub_tree embedding 由merge后的结果得到\n",
    "                ld = self.dropout(l)                                       # ld = sub-tree left tree embedding\n",
    "                c  = self.dropout(c)                                       # h_r\n",
    "                g  = torch.tanh(   self.concat_r( torch.cat((ld, c), 1)))  # Q_{re}\n",
    "                t  = torch.sigmoid(self.concat_rg(torch.cat((ld, c), 1)))  # g_r\n",
    "                current_node_temp.append(g * t)                            # q_r\n",
    "        # len(current_node_temp): batch_size\n",
    "        # current_node_temp item: [1, hidden_size]\n",
    "\n",
    "        current_node = torch.stack(current_node_temp)\n",
    "        current_embeddings = self.dropout(current_node)\n",
    "        # current_node: goal vector q\n",
    "        # current_node: [batch_size, 1, hidden_size]\n",
    "\n",
    "        # current_embeddings: goal vector q\n",
    "        # encoder_outputs:    final hidden state h_{s}^{p}\n",
    "\n",
    "        # current_embeddings: [1,       batch_size, hidden_size]\n",
    "        # encoder_outputs:    [seq_len, batch_size, hidden_size]\n",
    "        current_attn = self.attn(current_embeddings.transpose(0, 1), encoder_outputs, seq_mask)\n",
    "        # 1. Top-Down Goal Decomposition\n",
    "        # current_attn: [batch_size, 1, seq_len]\n",
    "\n",
    "        # current_attn:    a_{s}\n",
    "        # encoder_outputs: final hidden state h_{s}^{p}\n",
    "        current_context = current_attn.bmm(encoder_outputs.transpose(0, 1))  # B x 1 x N\n",
    "        # 1. Top-Down Goal Decomposition\n",
    "        # current_context: context vector c\n",
    "        # current_context: [batch_size, 1, hidden_size]\n",
    "\n",
    "        # the information to get the current quantity\n",
    "        batch_size = current_embeddings.size(0)\n",
    "        # predict the output (this node corresponding to output(number or operator)) with PADE\n",
    "\n",
    "        repeat_dims = [1] * self.embedding_weight.dim()\n",
    "        repeat_dims[0] = batch_size\n",
    "\n",
    "        # constant_size = input_size\n",
    "        # self.embedding_weight: [         1, constant_size, hidden_size]\n",
    "        # embedding_weight:      [batch_size, constant_size, hidden_size]\n",
    "        embedding_weight = self.embedding_weight.repeat(*repeat_dims)  # B x input_size x N\n",
    "\n",
    "        # embedding_weight:   [batch_size, constant_size, hidden_size]\n",
    "        # num_pades:          [batch_size, num_size,      hidden_size]\n",
    "        embedding_weight = torch.cat((embedding_weight, num_pades), dim=1)  # B x O x N\n",
    "        # embedding_weight:   [batch_size, num_size + constant_size, hidden_size]\n",
    "\n",
    "        # 1. Top-Down Goal Decomposition\n",
    "        # current_node:    goal    vector q\n",
    "        # current_context: context vector c\n",
    "        leaf_input = torch.cat((current_node, current_context), 2)\n",
    "        # leaf_input: concat(q; c)\n",
    "        # leaf_input: [batch_size, 1, 2*hidden_size]\n",
    "\n",
    "        leaf_input = leaf_input.squeeze(1)\n",
    "        # leaf_input: [batch_size, 2*hidden_size]\n",
    "\n",
    "        leaf_input = self.dropout(leaf_input)\n",
    "        # leaf_input: [batch_size, 2*hidden_size]\n",
    "\n",
    "        # max pooling the embedding_weight\n",
    "        # embedding_weight: [batch_size, num_size + constant_size, hidden_size]\n",
    "\n",
    "        # embedding_weight_: token embedding e(y|P)\n",
    "        embedding_weight_ = self.dropout(embedding_weight)\n",
    "        # embedding_weight_: [batch_size, num_size + constant_size, hidden_size]\n",
    "\n",
    "        # leaf_input.unsqueeze(1): [batch_size, 1, 2*hidden_size]\n",
    "        num_score = self.score(leaf_input.unsqueeze(1), embedding_weight_, mask_nums)\n",
    "        # num_score: [batch_size, num_size + constant_size]\n",
    "\n",
    "        # op: [batch_size, op_num]\n",
    "        op = self.ops(leaf_input)\n",
    "        return num_score, op, current_node, current_context, embedding_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始时  \n",
    "  \n",
    "* **node_stacks:** \\[TreeNode\\], TreeNode.embedding = problem_output = \\[1, hidden\\_size\\]\n",
    "* **embedding\\_stacks:** \\[\\]\n",
    "* **left_childs:** \\[None\\]\n",
    "```python\n",
    "for st in node_stacks:  # node_stacks记录节点的goal vector q\n",
    "    if len(st) == 0:\n",
    "        current_embeddings.append(padding_hidden)\n",
    "    else:\n",
    "        current_node = st[-1]\n",
    "        current_embeddings.append(current_node.embedding)\n",
    "```\n",
    "  \n",
    "**current_embeddings**: \\[embedding\\] = \\[1, hidden\\_size\\]  \n",
    "  \n",
    "此时**left_childs**为空\n",
    "$$Q_{le} = tanh(W_{le} h_{l})$$\n",
    "$$g_{l} = \\sigma(W_{gl} h_{l}$$\n",
    "$$q_{l} = g_{l} * Q_{le}$$\n",
    "**current_node_temp** = \\[$q_{l}$\\]\n",
    "```python\n",
    "current_node_temp = []  # updated goal vector q\n",
    "for l, c in zip(left_childs, current_embeddings):\n",
    "    if l is None:  # left sub-tree embedding is None, generate left child node\n",
    "        # 2. Left Sub-Goal Generation\n",
    "        # 若此时左子树为空，则生成左孩子节点\n",
    "        c = self.dropout(c)                   # h_l\n",
    "        g = torch.tanh(self.concat_l(c))   # Q_{le}\n",
    "        t = torch.sigmoid(self.concat_lg(c))  # g_l\n",
    "        current_node_temp.append(g * t)       # q_l\n",
    "```\n",
    "  \n",
    "Top-down Goal Decomposition\n",
    "* **current_node:** goal vector $q$\n",
    "* **encoder_outputs:** encoder outputs $h_{s}^{p}$\n",
    "  \n",
    "**Tree Attention**  \n",
    "$$c = \\sum\\limits_{s} a_{s} h_{s}^{p}$$\n",
    "* **current_attn:** $a_{s}$\n",
    "* **current_context:** context vector $c$\n",
    "  \n",
    "```python\n",
    "current_node = torch.stack(current_node_temp)\n",
    "current_embeddings = self.dropout(current_node)\n",
    "\n",
    "# current_embeddings: [1,       batch_size, hidden_size]\n",
    "# encoder_outputs:    [seq_len, batch_size, hidden_size]\n",
    "current_attn = self.attn(current_embeddings.transpose(0, 1), encoder_outputs, seq_mask)\n",
    "# 1. Top-Down Goal Decomposition\n",
    "# current_attn: [batch_size, 1, seq_len]\n",
    "\n",
    "# current_attn:    a_{s}\n",
    "# encoder_outputs: final hidden state h_{s}^{p}\n",
    "current_context = current_attn.bmm(encoder_outputs.transpose(0, 1))  # B x 1 x N\n",
    "```\n",
    "  \n",
    "* **embedding_weight:** constant_number embedding\n",
    "* **num_pades:** text number embedding\n",
    "* **embedding_weight:** number embedding = token embedding $e(y|P)$\n",
    "\n",
    "```python\n",
    "embedding_weight = torch.cat((embedding_weight, num_pades), dim=1)  # B x O x N\n",
    "# embedding_weight:   [batch_size, num_size + constant_size, hidden_size]\n",
    "\n",
    "# 1. Top-Down Goal Decomposition\n",
    "# current_node:    goal   vector q\n",
    "# current_context:  context vector c\n",
    "leaf_input = torch.cat((current_node, current_context), 2)\n",
    "num_score = self.score(leaf_input.unsqueeze(1), embedding_weight_, mask_nums)\n",
    "op = self.ops(leaf_input)\n",
    "```\n",
    "\n",
    "**Score:**\n",
    "* $hidden = leaf\\_input$\n",
    "* $energy\\_in = [q, c, e(y|P)$]\n",
    "  \n",
    "$$score = s(y|q, c, P) = w_{n}^{\\top} tanh(W_{s} [q, c, e(y|P)])$$\n",
    "```python\n",
    "energy_in = torch.cat((hidden, num_embeddings), 2)\n",
    "score = self.score(torch.tanh(self.attn(energy_in)))  # (B x O) x 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeAttn(nn.Module):\n",
    "    ...\n",
    "    def forward(self, hidden, encoder_outputs, seq_mask=None):\n",
    "            ...\n",
    "        energy_in = torch.cat((hidden, encoder_outputs), 2)\n",
    "        # energy_in: [seq_len, batch_size, 2*hidden_size]\n",
    "\n",
    "        energy_in = energy_in.view(-1, self.input_size + self.hidden_size)\n",
    "        # energy_in: [seq_len * batch_size, 2*hidden_size]\n",
    "\n",
    "        score_feature = torch.tanh(self.attn(energy_in))\n",
    "        # score_feature: [seq_len * batch_size, hidden_size]\n",
    "\n",
    "        # 1. Top-Down Goal Decomposition\n",
    "        # attn_energies: score(q; h_s^{p})\n",
    "\n",
    "        # attn_energies: [seq_len * batch_size, 1]\n",
    "        attn_energies = self.score(score_feature)  # (S x B) x 1\n",
    "\n",
    "        # attn_energies: [seq_len * batch_size]\n",
    "        attn_energies = attn_energies.squeeze(1)\n",
    "\n",
    "        # attn_energies: [batch_size, seq_len]\n",
    "        attn_energies = attn_energies.view(max_len, this_batch_size).transpose(0, 1)  # B x S\n",
    "\n",
    "        if seq_mask is not None:\n",
    "            attn_energies = attn_energies.masked_fill_(seq_mask, -1e12)\n",
    "\n",
    "        # attn_energies: [batch_size, seq_len]\n",
    "        # 1. Top-Down Goal Decomposition\n",
    "        # attn_energies: a_{s}\n",
    "        attn_energies = nn.functional.softmax(attn_energies, dim=1)  # B x S\n",
    "\n",
    "        return attn_energies.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TreeAttn:**\n",
    "  \n",
    "* **hidden:** goal vector $q$\n",
    "* **encoder_outputs:** encoder output $h_{s}^{p}$\n",
    "  \n",
    "$$score(q, h_{s}^{p}) = v_{a}^{\\top} tanh(W_{a} [q, h_{s}^{p}]$$\n",
    "```python\n",
    "    energy_in = torch.cat((hidden, encoder_outputs), 2)\n",
    "    # energy_in: [seq_len, batch_size, 2*hidden_size]\n",
    "\n",
    "    energy_in = energy_in.view(-1, self.input_size + self.hidden_size)\n",
    "    # energy_in: [seq_len * batch_size, 2*hidden_size]\n",
    "\n",
    "    score_feature = torch.tanh(self.attn(energy_in))\n",
    "    # score_feature: [seq_len * batch_size, hidden_size]\n",
    "\n",
    "    # 1. Top-Down Goal Decomposition\n",
    "    # attn_energies: score(q; h_s^{p})\n",
    "\n",
    "    # attn_energies: [seq_len * batch_size, 1]\n",
    "    attn_energies = self.score(score_feature)  # (S x B) x 1\n",
    "```\n",
    "  \n",
    "$$a_{s} = \\frac{exp(score(q, h_{s}^{p})}{\\sum_{i} exp(score(q, h_{i}^{p})}$$\n",
    "```python\n",
    "attn_energies = nn.functional.softmax(attn_energies, dim=1)  # B x S\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateNode(nn.Module):\n",
    "    ...\n",
    "    def forward(self, node_embedding, node_label, current_context):\n",
    "        # 得到当前operator的token embedding\n",
    "        node_label_ = self.embeddings(node_label)\n",
    "        # node_label_: [batch_size, embedding_size]\n",
    "\n",
    "        node_label = self.em_dropout(node_label_)\n",
    "        # node_label:  [batch_size, embedding_size]\n",
    "\n",
    "        # 2. Left Sub-Goal Generation\n",
    "        # node_embedding:  parent goal    vector q\n",
    "        # current_context: parent context vector c\n",
    "        # node_label:      parent token embedding e(y^|P)\n",
    "\n",
    "        l_child   = torch.tanh(   self.generate_l( torch.cat((node_embedding, current_context, node_label), 1)))  # o_l\n",
    "        # l_child:   [batch_size, hidden_size]\n",
    "        l_child_g = torch.sigmoid(self.generate_lg(torch.cat((node_embedding, current_context, node_label), 1)))  # C_l\n",
    "        # l_child_g: [batch_size, hidden_size]\n",
    "        l_child   = l_child * l_child_g  # h_l\n",
    "        # l_child:   [batch_size, hidden_size]\n",
    "\n",
    "        # 3. Right Sub-Goal Generation\n",
    "        # node_embedding:  parent goal    vector q\n",
    "        # current_context: parent context vector c\n",
    "        # node_label:      parent token embedding e(y^|P)\n",
    "\n",
    "        r_child   = torch.tanh(   self.generate_r( torch.cat((node_embedding, current_context, node_label), 1)))  # o_r\n",
    "        # l_child:   [batch_size, hidden_size]\n",
    "        r_child_g = torch.sigmoid(self.generate_rg(torch.cat((node_embedding, current_context, node_label), 1)))  # C_r\n",
    "        # l_child_g: [batch_size, hidden_size]\n",
    "        r_child   = r_child * r_child_g  # h_r\n",
    "        # l_child:   [batch_size, hidden_size]\n",
    "        return l_child, r_child, node_label_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generete**  \n",
    "  \n",
    "* **node_embedding**: goal vector $q$\n",
    "* **current_context**: context vector $c$\n",
    "* **node_label**: target seq token index\n",
    "* **node_label_**: token embedding $e(y|P)$\n",
    "  \n",
    "**left child generation**\n",
    "$$l\\_child = o_{l} = \\sigma(W_{ol}[q, c, e(\\hat{y}|P)])$$\n",
    "$$l\\_child\\_g = C_{l} = tanh(W_{cl} [q, c, e(\\hat{y}|P)])$$\n",
    "$$l\\_child = h_{l} = o_{l} \\odot C_{l}$$\n",
    "**right child generation**\n",
    "\n",
    "$$r\\_child = o_{r} = \\sigma(W_{or}[q, c, e(\\hat{y}|P)])$$\n",
    "$$r\\_child\\_g = C_{r} = tanh(W_{cr} [q, c, e(\\hat{y}|P)])$$\n",
    "$$r\\_child = h_{r} = o_{r} \\odot C_{r}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
